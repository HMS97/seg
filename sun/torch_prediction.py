from PIL import Image
import cv2
from path import Path
from utils.datasets import SlippyMapTilesConcatenation
import collections
import torch
import torch.backends.cudnn
from torch.nn import DataParallel
from torch.optim import Adam
from torch.utils.data import DataLoader
from torchvision import transforms
from torch.utils.data import Dataset
import torchvision.transforms.functional as tf
import segmentation_models_pytorch as smp
from utils.loss import CrossEntropyLoss2d, mIoULoss2d, FocalLoss2d, LovaszLoss2d
from utils.transforms import (
    JointCompose,
    JointTransform,
    JointRandomHorizontalFlip,
    JointRandomRotation,
    ConvertImageMode,
    ImageToTensor,
    MaskToTensor,
)
from torchvision.transforms import Resize, CenterCrop, Normalize
from utils.metrics import Metrics
from models.segnet.segnet import segnet
from models.unet.unet import UNet
import random
import os
import tqdm
import json
import numpy as np
from skimage import io

## need to create a file to store temp pictures
try:
    shutil.rmtree('temp_pic')    #递归删除文件夹
except:
    pass
os.makedirs('temp_pic')
path = './temp_pic/'


device = 'cuda'
# predict on one model
model = torch.load('model/unet_2019-07-21.pth')
# give the picture you want to predict



def get_pascal_labels():
    """Load the mapping that associates pascal classes with label colors

    Returns:
        np.ndarray with dimensions (21, 3)
    """
    return np.array([
        [  0,   0,   0],
        [0, 200 ,0],
       [150, 250,   0],
       [150, 200, 150],
       [200,   0, 200],
       [150,   0, 250],
       [150, 150, 250],
       [250, 200,   0],
       [200, 200,   0],
       [200,   0,   0],
       [250,   0, 150],
       [200, 150, 150],
       [250, 150, 150],
       [  0,   0, 200],
       [  0, 150, 200],
       [  0, 200, 250]])


def decode_segmap(label_mask, plot=False):
    """Decode segmentation class labels into a color image

    Args:
        label_mask (np.ndarray): an (M,N) array of integer values denoting
          the class label at each spatial location.
        plot (bool, optional): whether to show the resulting color image
          in a figure.

    Returns:
        (np.ndarray, optional): the resulting decoded color image.
    """
    label_colours = get_pascal_labels()
    r = label_mask.copy()
    g = label_mask.copy()
    b = label_mask.copy()
    for ll in range(0, len(label_colours)):
        r[label_mask == ll] = label_colours[ll, 0]
        g[label_mask == ll] = label_colours[ll, 1]
        b[label_mask == ll] = label_colours[ll, 2]
    rgb = np.zeros((label_mask.shape[0], label_mask.shape[1], 3))
    rgb[:, :, 0] = r
    rgb[:, :, 1] = g
    rgb[:, :, 2] = b 
    if plot:
        plt.imshow(rgb)
        plt.show()
    else:
        return rgb.astype(int)
    

## use model to predict
def predict(model):
    model.eval()
    result = []
    for images in tqdm.tqdm(test_loader):
        images = images.to(device)
        outputs = model(images)
        probs = torch.max(outputs,1)[1]
        result.append(decode_segmap(probs.cpu().numpy().reshape(512,512),False))
    return result




def input_and_output(pic_path,model,generate_data):
    """
    args:
        pic_path : the picture you want to predict
        model    : the model you want to predict
    note:
        step one : generate some pictures from one picture
        step two : predict from the images generated by step one 
    """
    stride = 512
    image_size = 512


    image = io.imread(f'{pic_path}')
    
    h,w,_ = image.shape
    padding_h = (h//stride + 1) * stride 
    padding_w = (w//stride + 1) * stride
    padding_img = np.zeros((padding_h,padding_w,4),dtype=np.uint8)
    padding_img[0:h,0:w,:] = image[:,:,:]

    padding_img = np.array(padding_img)
#     print ('src:',padding_img.shape)
    mask_whole = np.zeros((padding_h,padding_w,3),dtype=np.uint8)

    if generate_data== False:
        result = predict(model)
        map_list = [str(i.name) for i in  Path('temp_pic').files()]
    for i in range(padding_h//stride):
        for j in range(padding_w//stride):
            crop = padding_img[i*stride:i*stride+image_size,j*stride:j*stride+image_size , :]
            ch,cw,_ = crop.shape
            if generate_data == True:
                cv2.imwrite(f'temp_pic/{i}_{j}.png',crop)
            if generate_data== False:
                mask_whole[i*stride:i*stride+image_size,j*stride:j*stride+image_size,0] = result[map_list.index(f'{i}_{j}.png')][:,:,0]
                mask_whole[i*stride:i*stride+image_size,j*stride:j*stride+image_size,1] = result[map_list.index(f'{i}_{j}.png')][:,:,1]
                mask_whole[i*stride:i*stride+image_size,j*stride:j*stride+image_size,2] = result[map_list.index(f'{i}_{j}.png')][:,:,2]

    return mask_whole[:image.shape[0],:image.shape[1]]

def get_dataset_loaders( workers):
    target_size = 512
    batch_size = 1

    mean, std = [0.485, 0.456, 0.406], [0.229, 0.224, 0.225]

    transform = JointCompose(
        [
            JointTransform(Resize(target_size, Image.BILINEAR), Resize(target_size, Image.NEAREST)),
            JointTransform(CenterCrop(target_size), CenterCrop(target_size)),
            JointRandomHorizontalFlip(0.5),
            JointRandomRotation(0.5, 90),
            JointRandomRotation(0.5, 90),
            JointRandomRotation(0.5, 90),
            JointTransform(ImageToTensor(), MaskToTensor()),
            JointTransform(Normalize(mean=mean, std=std), None),
        ]
    )

    test_dataset = SlippyMapTilesConcatenation(
        os.path.join(path),'./' , transform,debug = False,test  = True
    )

    test_loader = DataLoader(test_dataset, batch_size=batch_size, num_workers=workers)

    return test_loader




for i in Path('test').files():
    # give the name you want to store
    save_dir = i.stem[:-4] + "_label.tif"   
    input_and_output(i,model,generate_data= True)
    test_loader = get_dataset_loaders(5)

    mask_result = input_and_output(i,model,generate_data= False)
    
    mask_result = mask_result.astype(int)
    mask_result = mask_result[:,:,::-1]
    cv2.imwrite(f'result/'+save_dir,mask_result)